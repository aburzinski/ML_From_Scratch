{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Necessary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bessel_var(X):\n",
    "    return np.var(X) / (len(X) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_probs(y):\n",
    "    probs = np.array([])\n",
    "    for k in np.unique(y):\n",
    "        probs = np.append(probs, np.sum(y == k) / len(y))\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_dist(X, y, col_type):\n",
    "    idx = (col_type == 'continuous')\n",
    "    X = X[:, idx]\n",
    "    mu = np.zeros([len(np.unique(y)), X.shape[1]])\n",
    "    sigma_sq = np.zeros([len(np.unique(y)), X.shape[1]])\n",
    "    for i in range(len(np.unique(y))):\n",
    "        idx = (y == np.unique(y)[i])\n",
    "        for j in range(X.shape[1]):\n",
    "            mu[i, j] =  np.mean(X[idx, j])\n",
    "            sigma_sq[i, j] = bessel_var(X[idx, j])\n",
    "    return (mu, sigma_sq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_probs(X, y, new_X, k, row, col):\n",
    "    idx = (y == np.unique(y)[k])\n",
    "    return np.mean(X[idx, col] == new_X[row, col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_prob(v, mu, sigma_sq):\n",
    "    return 1 / np.sqrt(2 * np.pi * sigma_sq) * np.exp(-1 * (v - mu) **2 / (2 * sigma_sq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_probs(X, y, new_X, col_type):\n",
    "    mu, sigma_sq = get_class_dist(X, y, col_type)\n",
    "    class_probs = get_class_probs(y)\n",
    "    probs = np.zeros([new_X.shape[0], len(np.unique(y))])\n",
    "    for row in range(new_X.shape[0]):\n",
    "        for k in range(len(np.unique(y))):\n",
    "            row_probs = np.array([])\n",
    "            for col in range(new_X.shape[1]):\n",
    "                if col_type[col] == 'continuous':\n",
    "                    row_probs = np.append(row_probs, gaussian_prob(new_X[row, col], mu[k, col], sigma_sq[k, col]))\n",
    "                elif col_type[col] == 'categorical':\n",
    "                    row_probs = np.append(row_probs, get_category_probs(X, y, new_X, k, row, col))\n",
    "            probs[row, k] = class_probs[k] * np.prod(row_probs)\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_class(probs, y):\n",
    "    classes = np.unique(y)\n",
    "    idx = np.argmax(probs, axis = 1)\n",
    "    return np.array([classes[i] for i in idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes_predict(train_X, train_y, test_X, col_types):\n",
    "    probs = calc_probs(train_X, train_y, test_X, col_types)\n",
    "    return select_class(probs, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Downsampling Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(X, y, larger_class, smaller_class):\n",
    "    larger_idx = np.where(y == larger_class)[0]\n",
    "    smaller_idx = np.where(y == smaller_class)[0]\n",
    "    new_larger_idx = np.random.choice(larger_idx, size = len(smaller_idx), replace = False)\n",
    "    new_X = X[new_larger_idx, :]\n",
    "    new_X = np.append(new_X, X[smaller_idx, :], axis = 0)\n",
    "    new_y = y[new_larger_idx]\n",
    "    new_y = np.append(new_y, y[smaller_idx])\n",
    "    return (new_X, new_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_X = np.array([[10, 13, 0],\n",
    "#               [12, 15, 0],\n",
    "#               [11, 17, 1],\n",
    "#               [12, 15, 0],\n",
    "#               [20, 16, 1],\n",
    "#               [19, 17, 1],\n",
    "#               [21, 13, 0],\n",
    "#               [21, 15, 1],\n",
    "#               [20, 14, 1]])\n",
    "\n",
    "# train_y = np.array([0, 0, 0, 0, 1, 1, 1, 1, 1])\n",
    "\n",
    "# test_X = np.array([[16, 16, 1],\n",
    "#                    [19, 15, 0]])\n",
    "\n",
    "# test_y = np.array([0, 1])\n",
    "\n",
    "breast_cancer = datasets.load_breast_cancer()\n",
    "wine = datasets.load_wine()\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "breast_cancer_cat = pd.read_csv('./Data/Naive Bayes/breast-cancer.data').values\n",
    "\n",
    "# X, y = downsample(breast_cancer_cat[:, 1:], breast_cancer_cat[:, 0], 'no-recurrence-events', 'recurrence-events')\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(breast_cancer_cat[:, 1:], breast_cancer_cat[:, 0],\n",
    "                                                    test_size = .3, random_state = 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['no-recurrence-events' 'no-recurrence-events' 'no-recurrence-events'\n",
      " 'no-recurrence-events' 'recurrence-events' 'no-recurrence-events'\n",
      " 'no-recurrence-events' 'recurrence-events' 'no-recurrence-events'\n",
      " 'no-recurrence-events' 'no-recurrence-events' 'no-recurrence-events'\n",
      " 'no-recurrence-events' 'no-recurrence-events' 'recurrence-events'\n",
      " 'no-recurrence-events' 'no-recurrence-events' 'no-recurrence-events'\n",
      " 'no-recurrence-events' 'recurrence-events' 'no-recurrence-events'\n",
      " 'no-recurrence-events' 'no-recurrence-events' 'no-recurrence-events'\n",
      " 'recurrence-events' 'no-recurrence-events' 'recurrence-events'\n",
      " 'no-recurrence-events' 'no-recurrence-events' 'no-recurrence-events'\n",
      " 'no-recurrence-events' 'no-recurrence-events' 'recurrence-events'\n",
      " 'no-recurrence-events' 'no-recurrence-events' 'recurrence-events'\n",
      " 'recurrence-events' 'no-recurrence-events' 'no-recurrence-events'\n",
      " 'no-recurrence-events' 'no-recurrence-events' 'no-recurrence-events'\n",
      " 'no-recurrence-events' 'no-recurrence-events' 'no-recurrence-events'\n",
      " 'recurrence-events' 'no-recurrence-events' 'no-recurrence-events'\n",
      " 'no-recurrence-events' 'no-recurrence-events' 'recurrence-events'\n",
      " 'recurrence-events' 'no-recurrence-events' 'no-recurrence-events'\n",
      " 'recurrence-events' 'no-recurrence-events' 'no-recurrence-events'\n",
      " 'no-recurrence-events' 'recurrence-events' 'no-recurrence-events'\n",
      " 'recurrence-events' 'no-recurrence-events' 'recurrence-events'\n",
      " 'no-recurrence-events' 'no-recurrence-events' 'no-recurrence-events'\n",
      " 'recurrence-events' 'recurrence-events' 'recurrence-events'\n",
      " 'recurrence-events' 'recurrence-events' 'no-recurrence-events'\n",
      " 'no-recurrence-events' 'no-recurrence-events' 'recurrence-events'\n",
      " 'no-recurrence-events' 'no-recurrence-events' 'no-recurrence-events'\n",
      " 'no-recurrence-events' 'no-recurrence-events' 'no-recurrence-events'\n",
      " 'no-recurrence-events' 'recurrence-events' 'no-recurrence-events'\n",
      " 'no-recurrence-events' 'no-recurrence-events']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7790697674418605"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = naive_bayes_predict(train_X, train_y, test_X, ['categorical' for _ in range(train_X.shape[1])])\n",
    "print(preds)\n",
    "np.mean(test_y == preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
